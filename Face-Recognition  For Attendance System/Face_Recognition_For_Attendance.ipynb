{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition  For Attendance ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNjurhlZYtBY"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# from PIL import ImageGrab\n",
        "\n",
        "path = 'Training_images'\n",
        "images = []\n",
        "classNames = []\n",
        "myList = os.listdir(path)\n",
        "print(myList)\n",
        "for cl in myList:\n",
        "    curImg = cv2.imread(f'{path}/{cl}')\n",
        "    images.append(curImg)\n",
        "    classNames.append(os.path.splitext(cl)[0])\n",
        "print(classNames)\n",
        "\n",
        "\n",
        "def findEncodings(images):\n",
        "    encodeList = []\n",
        "\n",
        "\n",
        "    for img in images:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        encode = face_recognition.face_encodings(img)[0]\n",
        "        encodeList.append(encode)\n",
        "    return encodeList\n",
        "\n",
        "\n",
        "def markAttendance(name):\n",
        "    with open('Attendance.csv', 'r+') as f:\n",
        "        myDataList = f.readlines()\n",
        "\n",
        "\n",
        "        nameList = []\n",
        "        for line in myDataList:\n",
        "            entry = line.split(',')\n",
        "            nameList.append(entry[0])\n",
        "            if name not in nameList:\n",
        "                now = datetime.now()\n",
        "                dtString = now.strftime('%H:%M:%S')\n",
        "                f.writelines(f'\\n{name},{dtString}')\n",
        "\n",
        "#### FOR CAPTURING SCREEN RATHER THAN WEBCAM\n",
        "# def captureScreen(bbox=(300,300,690+300,530+300)):\n",
        "#     capScr = np.array(ImageGrab.grab(bbox))\n",
        "#     capScr = cv2.cvtColor(capScr, cv2.COLOR_RGB2BGR)\n",
        "#     return capScr\n",
        "\n",
        "encodeListKnown = findEncodings(images)\n",
        "print('Encoding Complete')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "# img = captureScreen()\n",
        "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
        "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    facesCurFrame = face_recognition.face_locations(imgS)\n",
        "    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
        "\n",
        "    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
        "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "# print(faceDis)\n",
        "        matchIndex = np.argmin(faceDis)\n",
        "\n",
        "        if matches[matchIndex]:\n",
        "            name = classNames[matchIndex].upper()\n",
        "# print(name)\n",
        "            y1, x2, y2, x1 = faceLoc\n",
        "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
        "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
        "            markAttendance(name)\n",
        "\n",
        "    cv2.imshow('Webcam', img)\n",
        "    cv2.waitKey(1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}